\documentclass[12pt, a4paper]{article}
\usepackage{hyperref}
\usepackage{indentfirst}
\usepackage[pdftex]{graphicx}

\title{Amazon Web Services}
\author{T-110.5150 - Applications and Services in Internet}
\date{Deadline: 4th December 2013, 23:59 Helsinki Time}
\begin{document}
\maketitle
\section{Introduction}

This assignment aims to introduce you to the cloud based Amazon Web Services (AWS)\footnote{\url{http://aws.amazon.com/}}, specifically Amazon Elastic Compute Cloud (EC2), Amazon Simple Storage Service (S3), and Amazon Elastic MapReduce.

In this assignment, you will:
\begin{itemize}
\item Gain practical experience in Amazon Web Services.
\item Investigate the scheduling behaviour among virtual machines.
\item Investigate the network throughput between EC2 instances within the same AWS Region.
\end{itemize}

\section{Description}
Each group will be assigned an Amazon account.
Account credentials will be distributed by e-mail and detailed instructions will be announced through Noppa\footnote{\url{https://noppa.aalto.fi/}}.

Monitor your account activity carefully.
Remember to turn off your instances before logging out from the management console.

Please clear your account at the end of this assignment by removing all your S3 buckets, terminating all your EC2 instances, and closing all other related services.
Previously some students were charged thousands of U.S. dollars since they forgot to terminate their instances at the end.
Although we found some way to resolve it, please try your best to avoid it.


\subsection{Basic features}
You must complete all of them to pass the assignment.

\subsubsection{Amazon S3 (15 pts)}
Create an Amazon S3 bucket in the EU West (Ireland) Region.
Upload files of different sizes (1KiB, 10KiB, 100KiB, 1MiB, 10MiB, etc) into your bucket and investigate the transfer throughput between your local machine and the EU West (Ireland) Region.
Use \emph{s3cmd}\footnote{\url{http://s3tools.org/s3cmd}} as the benchmark tool.In addition, you may also use other tools with which you are familiar.

\subsubsection{Amazon EC2 and scheduling behaviour (30 pts)}
The purpose of this experiment is to determine whether your instance (which is a virtual machine) is sharing the physical processor with other instances or not.
One way to achieve this is to get the system time continuously, for example, by invoking the \texttt{gettimeofday()} system call.
If your instance occupies the processor exclusively the system time should be continuous without any noticeable gap.
If the processor is shared with other instances some gaps in system time are anticipated.
These are the periods in which your instance is scheduled off and the processor is yielded to other instances.

You are asked to experiment with two types of Amazon EC2 instances: Micro and Small.
All instances shall be launched using 64-bit Amazon Linux Amazon Machine Image (AMI).
The latest version of the AMI is 2013.09 and the AMI ID for EU West Region is \texttt{ami-149f7863}.
You may find the AWS documentation useful.\footnote{\url{http://docs.amazonwebservices.com/AWSEC2/latest/GettingStartedGuide/}}

Please implement a small application which retrieves current system time as fine-grained as possible, such as invoking the \texttt{gettimeofday()} system call one million times in a loop.
Collect system time stamps from both the Micro and the Small instances and analyse the data.
Compute the CPU utilisation ratio for both instances and plot your data.
Explain your findings.

You may use any tool for graph plotting.
Here we list some possible candidates: LibreOffice Calc, MATLAB, or GNU Plot\footnote{\url{http://www.gnuplot.info/}}.

\subsubsection{Amazon EC2 network throughput (30 pts)}
Launch two pairs of instances (Micro-Micro and Small-Small) in the EU West Region using the aforementioned AMI.
Implement applications to investigate TCP and UDP throughput between the pairs of instances.

Whether TCP or UDP, a throughput measurement program consists of two parts: the client and the server.
The client side acts as the sender and the server acts as the receiver.
In the client side a file is read and transmitted.
In the server side you record the time elapsed for every 256KiB data received.

In order to boost the performance of TCP, the sending buffer in the client and the receiving buffer in the server need to be enlarged to 256KiB.
Enlarging these buffers will expand the sending and receiving window size of TCP.
In C, this is achieved by \texttt{setsockopt()} system call with options \texttt{SO\_SNDBUF} and \texttt{SO\_RCVBUF}.
In Java, please check \texttt{setSendBufferSize()} and \texttt{setReceiveBufferSize()} methods in the class \texttt{java.net.Socket}.

For UDP experiment, each UDP packet from the client shall carry a payload of 1024 bytes.

Plot two figures out of the data: one for TCP throughput and one for UDP throughput.
Then calculate the average throughput for the whole transmission.
Compare the difference between the Micro-Micro pair and the Small-Small pair.
Explain your findings and how this is related to the results from the previous CPU utilisation experiment.
\subsection{Additional features}
Choose at most two of them.

\subsubsection{MapReduce (25 pts)}
Test Amazon Elastic MapReduce with the sample job named "WordCount (Streaming)".\footnote{\url{http://s3.amazonaws.com/awsVideos/AmazonElasticMapReduce/AmazonElasticMapReduce.html}} Instead of using the predefined input, upload the Ulysses by James Joyce\footnote{http://www.gutenberg.org/ebooks/4300} to one of your buckets.
Run the job in small and large instances. Report the completion time for the tasks (you should enable and check the logs) and the most recurrent word.

Check the code for the splitter\footnote{https://s3.amazonaws.com/elasticmapreduce/samples/wordcount/wordSplitter.py}. Write a new splitter that counts the different bigrams\footnote{http://en.wikipedia.org/wiki/Bigram} present in the Ulysses. You don't need to write your splitter in Python, Amazon Elastic MapReduce Streaming jobs supports the following languages: Ruby, Perl, Python, PHP, R, Bash, or C++.

Run the job in small and large instances. Report the completion time for the tasks (you should enable and check the logs) and the most recurrent bigram.
\subsubsection{Create your own AMI (25 pts)}
Experiment with the process of creating your own AMI.\footnote{\url{http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/creating-an-ami.html}}

\subsubsection{P2P integration (25 pts)}
If you implemented a full feature P2P application in the first assignment you can deploy the application to some EC2 nodes.
For example, five peers in each of the five EC2 instances.
Analyse the topology and the search behaviour in your P2P network by varying parameters of the P2P application, such as max number of peers, max number of Pong entries in one Pong message, or different algorithms to select peers to be filled in a Pong message.
Describe your experiment setup and your findings.

\subsubsection{Amazon API and your own idea (25 pts)}
Do you have your own idea?
Use Amazon API to develop your own service.
Note that you may be requested for a demo of your own service.

\section{Submission}
The final report shall include the following elements:

\begin{itemize}
\item The process of the experiment, results, and analysis for each basic feature.
\item The process of the experiment and other related contents (mentioned in the requirement) for the additional features.
\item Feedback about the assignment.
\end{itemize}

Please create a new directory called ``\texttt{assignment\_2}'' in your repository and submit the final report and all source code of the programs used in this assignment into this directory.

There is no demo for this assignment except possibly for your own idea with Amazon API.

\section{Grading}
Experimenting with basic features is enough to pass the assignment.
You gain more points by trying some additional features.

The basic features are rather fixed, but you have free hands to try out additional features.
With freedom comes responsibility, you should report your experience with proper documentation.

\begin{itemize}
\item Basic features: 75 points.
\item Additional features: 25 points each (maximum 2 features).
\item Final report: 20 points.
\item Finishing the surveys: 10 points.
\end{itemize}

fail --- $<$ 75 points, a missing basic feature \emph{or} no report.

1 --- $\ge$ 75 points.

2 --- $\ge$ 95 points.

3 --- $\ge$ 115 points.

4 --- $\ge$ 130 points.

5 --- $\ge$ 145 points.

\vskip 20pt

Total: 160 points

\vskip 20pt

The first assignment and this assignment each accounts for 20\% in the whole course grading.
In other words, the percentage of the whole assignment part is 40\% and the other 60\% is the final exam.

\end{document}
